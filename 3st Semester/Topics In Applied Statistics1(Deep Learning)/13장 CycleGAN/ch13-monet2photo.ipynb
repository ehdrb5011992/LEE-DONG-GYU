{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "# import tensorflow as tf\n",
    "# config=tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# tf.keras.backend.set_session(tf.Session(config=config))\n",
    "\n",
    "from tensorflow.keras.layers import Activation,Dense,Input,concatenate\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Conv2DTranspose, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Reshape, Dropout,ZeroPadding2D,Add, add\n",
    "from tensorflow.keras import backend as k\n",
    "#from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "#from models.layers.layers import ReflectionPadding2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\82104\\\\Desktop\\\\대학원 수업\\\\2학년 1학기\\\\응용통계학특수연구1 (딥러닝)\\\\13장 CycleGAN',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\python37.zip',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\DLLs',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37',\n",
       " '',\n",
       " 'C:\\\\Users\\\\82104\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\82104\\\\.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"C:/Users/82104/Desktop/대학원 수업/2학년 1학기/응용통계학특수연구1 (딥러닝)/13장 CycleGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\82104\\\\Desktop\\\\대학원 수업\\\\2학년 1학기\\\\응용통계학특수연구1 (딥러닝)\\\\13장 CycleGAN',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\python37.zip',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\DLLs',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37',\n",
       " '',\n",
       " 'C:\\\\Users\\\\82104\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages',\n",
       " 'c:\\\\users\\\\82104\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\82104\\\\.ipython',\n",
       " 'C:/Users/82104/Desktop/대학원 수업/2학년 1학기/응용통계학특수연구1 (딥러닝)/13장 CycleGAN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monet2photo\n",
    "import instancenormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_unet(input_shape,output_shape,kernel_size,gen_n_filters):\n",
    "    def encoder(layer_input,filters,strides=2,activation='relu'):\n",
    "        d=Conv2D(filters,kernel_size=kernel_size,strides=strides,padding='same')(layer_input)\n",
    "        d=instancenormalization.instancenormalization.InstanceNormalization(axis=-1,center=False, scale=False)(d)\n",
    "        #d=BatchNormalization(axis=-1, center=False, scale=False)(d)\n",
    "        if activation=='relu':\n",
    "            d=Activation('relu')(d)\n",
    "        else:\n",
    "            d=LeakyReLU(alpha=0.2)(d)\n",
    "        return d\n",
    "    \n",
    "    def decoder(layer_input,concate_input,filters):\n",
    "        u=Conv2DTranspose(filters,kernel_size=kernel_size,strides=2,padding='same')(layer_input)\n",
    "        u=instancenormalization.InstanceNormalization(axis=-1, center=False, scale=False)(u)\n",
    "        #u=BatchNormalization(axis=-1, center=False, scale=False)(u)\n",
    "        u=Activation('relu')(u)\n",
    "        u=concatenate([u,concate_input])\n",
    "        return u\n",
    "    \n",
    "    img=Input(shape=input_shape)\n",
    "    channels=int(output_shape[-1])\n",
    "    \n",
    "    d1=encoder(img, gen_n_filters,strides=1,activation='notrelu')\n",
    "    d2=encoder(d1,gen_n_filters*2,activation='notrelu')\n",
    "    d3=encoder(d2, gen_n_filters*4,activation='notrelu')\n",
    "    d4=encoder(d3, gen_n_filters*8,activation='notrelu')\n",
    "    u1=decoder(d4,d3, gen_n_filters*4)\n",
    "    u2=decoder(u1,d2, gen_n_filters*2)\n",
    "    u3=decoder(u2,d1, gen_n_filters)\n",
    "    \n",
    "    output=Conv2DTranspose(channels,kernel_size=kernel_size, strides=1, padding='same', activation='relu')(u3)\n",
    "    generator=Model(img,output)\n",
    "    return generator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_resnet(input_shape,output_shape,kernel_size,gen_n_filters):\n",
    "    def conv7s1(layer_input,filters,final):\n",
    "        #y=tf.pad(layer_input,[[0,0],[3,3],[3,3],[0,0]],'REFLECT')\n",
    "        #y=Conv2D(filters,kernel_size=(7,7),strides=1,padding='valid')(y)\n",
    "        y=Conv2D(filters,kernel_size=(7,7),strides=1,padding='same')(layer_input)\n",
    "        if final:\n",
    "            y=Activation('tanh')(y)\n",
    "            #y=LeakyReLU(alpha=0.2)(y)\n",
    "        else:\n",
    "            y=instancenormalization.InstanceNormalization(axis=-1,center=False, scale=False)(y)\n",
    "            #y=BatchNormalization(axis=-1,center=False,scale=False)(y)\n",
    "            y=Activation('relu')(y)\n",
    "        return y\n",
    "    def encoder(layer_input,filters):\n",
    "        y=Conv2D(filters,kernel_size=kernel_size,strides=2,padding='same')(layer_input)\n",
    "        y=instancenormalization.InstanceNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        #y=BatchNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        y=Activation('relu')(y)\n",
    "        return y\n",
    "    def residual(layer_input,filters):\n",
    "        short_cut=layer_input\n",
    "        #y=tf.pad(layer_input,[[0,0],[1,1],[1,1],[0,0]],'REFLECT')\n",
    "        #y=Conv2D(filters,kernel_size=kernel_size,strides=1,padding='valid')(y)\n",
    "        y=Conv2D(filters,kernel_size=kernel_size,strides=1,padding='same')(layer_input)\n",
    "        y=instancenormalization.InstanceNormalization(axis=-1, center=False, scale=False)(y)\n",
    "       # y=Conv2D(filters,kernel_size=kernel_size,strides=1,padding='same')(layer_input)\n",
    "        #y=BatchNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        y=Activation('relu')(y)\n",
    "        \n",
    "        #y=tf.pad(layer_input,[[0,0],[1,1],[1,1],[0,0]],'REFLECT')\n",
    "        #y=Conv2D(filters,kernel_size=kernel_size,strides=1,padding='valid')(y)\n",
    "        y=Conv2D(filters,kernel_size=kernel_size,strides=1,padding='same')(y)\n",
    "        y=instancenormalization.InstanceNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        #y=BatchNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        \n",
    "        return add([short_cut,y])\n",
    "    \n",
    "    def decoder(layer_input,filters):\n",
    "        y=Conv2DTranspose(filters,kernel_size=kernel_size,strides=2,padding='same')(layer_input)\n",
    "        y=instancenormalization.InstanceNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        #y=BatchNormalization(axis=-1, center=False, scale=False)(y)\n",
    "        y=Activation('relu')(y)\n",
    "        return y\n",
    "    \n",
    "    img=Input(shape=input_shape)\n",
    "    channels=output_shape[-1]\n",
    "    y=conv7s1(img,gen_n_filters,False)\n",
    "    y=encoder(y,gen_n_filters*2)\n",
    "    y=encoder(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=residual(y,gen_n_filters*4)\n",
    "    y=decoder(y,gen_n_filters*2)\n",
    "    y=decoder(y,gen_n_filters)\n",
    "    output=conv7s1(y,channels,True)\n",
    "    generator=Model(img,output)\n",
    "    return generator\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape,kernel_size,dis_n_filters,patchgan=False):\n",
    "    def conv(layer_input,filters,strides=2,norm=True):\n",
    "        y=Conv2D(filters,kernel_size=4,strides=strides,padding='same')(layer_input)\n",
    "        if norm:\n",
    "            y=instancenormalization.InstanceNormalization(axis=-1, center=False, scale=False)(y)\n",
    "            #y=BatchNormalization(axis=-1, center=False,scale=False)(y)\n",
    "        y=LeakyReLU(0.2)(y)\n",
    "        return y\n",
    "    img=Input(shape=input_shape)\n",
    "    y=conv(img,dis_n_filters,strides=2,norm=False)\n",
    "    y=conv(y,dis_n_filters*2,strides=2,norm=True)\n",
    "    y=conv(y,dis_n_filters*4,strides=2,norm=True)\n",
    "    y=conv(y,dis_n_filters*8,strides=2,norm=True)\n",
    "    y=conv(y,dis_n_filters*8,strides=1,norm=True)\n",
    "    if patchgan:\n",
    "        output=Conv2D(1,kernel_size=kernel_size,padding='same')(y)\n",
    "    else:\n",
    "        y=Flatten()(y)\n",
    "        y=Dense(1)(y)\n",
    "        output=Activation('linear')(y)\n",
    "    discriminator=Model(img,output)\n",
    "    return discriminator\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cyclegan(shapes,dis_n_filters,gen_n_filters,kernel_size,unet=False,patchgan=False,identity=False):\n",
    "    A_shape, B_shape=shapes\n",
    "    d_A=build_discriminator(A_shape,kernel_size,dis_n_filters,patchgan=patchgan)\n",
    "    d_B=build_discriminator(B_shape,kernel_size,dis_n_filters,patchgan=patchgan)\n",
    "    d_A.summary()\n",
    "    d_B.summary()\n",
    "    d_A.compile(loss='mse',optimizer=Adam(0.0002,0.5))\n",
    "    d_B.compile(loss='mse',optimizer=RMSprop(0.0002,0.5))\n",
    "    \n",
    "    if unet:\n",
    "        g_AB=build_generator_unet(A_shape,B_shape,kernel_size,gen_n_filters)\n",
    "        g_BA=build_generator_unet(B_shape,A_shape,kernel_size,gen_n_filters)\n",
    "    else:\n",
    "        g_AB=build_generator_resnet(A_shape,B_shape,kernel_size,gen_n_filters)\n",
    "        g_BA=build_generator_resnet(B_shape,A_shape,kernel_size,gen_n_filters)\n",
    "    \n",
    "    d_A.trainable=False\n",
    "    d_B.trainable=False\n",
    "    g_AB.summary()\n",
    "    g_BA.summary()\n",
    "    img_A=Input(shape=A_shape)\n",
    "    img_B=Input(shape=B_shape)\n",
    "    fake_A=g_BA(img_B)\n",
    "    fake_B=g_AB(img_A)\n",
    "    valid_A=d_A(fake_A)\n",
    "    valid_B=d_B(fake_B)\n",
    "    recons_A=g_BA(fake_B)\n",
    "    recons_B=g_AB(fake_A)\n",
    "    \n",
    "    if identity:\n",
    "        img_A_id=g_BA(img_A)\n",
    "        img_B_id=g_AB(img_B)\n",
    "        inputs=[img_A, img_B]\n",
    "        outputs=[valid_A, valid_B, recons_A, recons_B, img_A_id, img_B_id]\n",
    "        loss=['mse','mse','mae','mae','mae','mae']\n",
    "        loss_weights=[1.,1.,10.,10.,5.,5.]\n",
    "    else:\n",
    "        inputs=[img_A,img_B]\n",
    "        outputs=[valid_A, valid_B, recons_A, recons_B]\n",
    "        loss=['mse','mse','mae','mae']\n",
    "        loss_weights=[1.,1.,10.,10.]\n",
    "    \n",
    "    adv=Model(inputs, outputs)\n",
    "    adv.compile(loss=loss, optimizer=Adam(0.0002,0.5), loss_weights=loss_weights)\n",
    "    #adv.summary()\n",
    "    return d_A, d_B, g_AB, g_BA, adv\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'monet2photo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f43b301f551e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmonet2photo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42880\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpatchgan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'monet2photo'"
     ]
    }
   ],
   "source": [
    "import monet2photo\n",
    "batch_size=1\n",
    "train_steps=42880\n",
    "patchgan=True\n",
    "identity=True\n",
    "save_interval=1072\n",
    "kernel_size=3\n",
    "gen_n_filters=32\n",
    "dis_n_filters=64\n",
    "\n",
    "\n",
    "data1=monet2photo.load_batch()\n",
    "data2=monet2photo.load_batch(is_train=False)\n",
    "A_data,B_data=data1\n",
    "test_A_data,test_B_data=data2\n",
    "\n",
    "height_A=A_data.shape[1]\n",
    "width_A=A_data.shape[2]\n",
    "channel_A=A_data.shape[3]\n",
    "A_shape=(height_A,width_A,channel_A)\n",
    "\n",
    "height_B=B_data.shape[1]\n",
    "width_B=B_data.shape[2]\n",
    "channel_B=B_data.shape[3]\n",
    "B_shape=(height_B,width_B,channel_B)\n",
    "\n",
    "print(A_data.shape)\n",
    "print(B_data.shape)\n",
    "print(test_A_data.shape)\n",
    "print(test_B_data.shape)\n",
    "\n",
    "shapes=(A_shape,B_shape)\n",
    "\n",
    "titles=('predicted monet images', \"predicted photo images\", 'reconstructed monet images','reconstructed photo images')\n",
    "B_size=int(B_data.shape[0])\n",
    "A_size=int(A_data.shape[0])\n",
    "\n",
    "models=build_cyclegan(shapes,gen_n_filters,dis_n_filters,kernel_size,patchgan=patchgan,identity=identity)\n",
    "d_A,d_B,g_AB,g_BA,adv=models\n",
    "\n",
    "if patchgan:\n",
    "    patch=int(A_data.shape[1]/2**4)\n",
    "else:\n",
    "    patch=1\n",
    "\n",
    "if patch>1:\n",
    "    d_patch=(patch,patch,1)\n",
    "    valid=np.ones((batch_size,)+d_patch)\n",
    "    fake=np.zeros((batch_size,)+d_patch)\n",
    "else:\n",
    "    valid=np.ones([batch_size,1])\n",
    "    fake=np.zeros([batch_size,1])\n",
    "    \n",
    "for step in range(train_steps):\n",
    "    rand_index=np.random.randint(0,B_size,size=batch_size)\n",
    "    real_B=B_data[rand_index]\n",
    "    rand_index=np.random.randint(0,A_size,size=batch_size)\n",
    "    real_A=A_data[rand_index]\n",
    "    \n",
    "    fake_B=g_AB.predict(real_A)\n",
    "    fake_A=g_BA.predict(real_B)\n",
    "    \n",
    "    dA_loss_real=d_A.train_on_batch(real_A, valid)\n",
    "    dA_loss_fake=d_A.train_on_batch(fake_A, fake)\n",
    "    dA_loss=0.5*np.add(dA_loss_real,dA_loss_fake)\n",
    "    log=\"%d:[d_A loss:%f]\" % (step+1,dA_loss)\n",
    "    \n",
    "    dB_loss_real=d_B.train_on_batch(real_B, valid)\n",
    "    dB_loss_fake=d_B.train_on_batch(fake_B, fake)\n",
    "    dB_loss=0.5*np.add(dB_loss_real,dB_loss_fake)\n",
    "    log='%s:[d_B loss:%f]' %(log,dB_loss)\n",
    "    \n",
    "    if identity:\n",
    "        adv_loss=adv.train_on_batch([real_A,real_B],[valid,valid,real_A, real_B,real_A,real_B])\n",
    "        log='%s[adv loss:%f]'%(log,adv_loss[0])\n",
    "    else:\n",
    "        adv_loss=adv.train_on_batch([real_A,real_B], [valid,valid,real_A, real_B])\n",
    "        log='%s[adv loss:%f]'%(log,adv_loss[0])\n",
    "    \n",
    "    if (step+1)%save_interval==0:\n",
    "        print(log)\n",
    "        if (step+1)==train_steps:\n",
    "            show=True\n",
    "        else:\n",
    "            show=True\n",
    "    \n",
    "        import other_utils\n",
    "        monet2photo.test_generator((g_BA, g_AB),(test_A_data,test_B_data), step=step+1, titles=titles,show=show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tf.keras.models import load_model\n",
    "g_AB.save('g_ABmonettophoto.h5')\n",
    "g_BA.save('g_BAmonet2photo.h5')\n",
    "\n",
    "#generator_AB=load_model('g_AB.h5')\n",
    "#generator_BA=load_model(''g_BA.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
