{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"yes_aug.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vwVmRuFcUBkT"},"source":["# [AlexNet]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jyk7Sp2m5ODF"},"source":["### Contents"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X8ffQ4gg5ODH"},"source":["1. Almost Original Alexnet\n","2. My Alexnet\n","```\n","1) Size = 64,\n","2) Size = 48,\n","```\n","3. Size = 48, No Early Stopping\n","```\n","1) Epoch = 50\n","2) Epoch = 100\n","```"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U01q4o40UBkY"},"source":["### Install Packages"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209763290,"user_tz":-540,"elapsed":15933,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"o1tpIlBhXG2i","outputId":"9ce29290-63f3-49b6-ad56-4241957ffeb4","colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209763292,"user_tz":-540,"elapsed":15915,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"IJdbC2nRXR6h","outputId":"f41e573a-aa1e-43d4-c66f-7713b2b7e1da","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My Drive/Colab Notebooks/project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bCx2JDrkW6sn","colab":{}},"source":["import sys"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209763294,"user_tz":-540,"elapsed":15898,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"qQKQi4SjY3Ug","outputId":"98f5445e-58a6-4d37-cc7b-a0dcc8923967","colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["# 모듈로 받을 경로 확인\n","sys.path"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '/env/python',\n"," '/usr/lib/python36.zip',\n"," '/usr/lib/python3.6',\n"," '/usr/lib/python3.6/lib-dynload',\n"," '/usr/local/lib/python3.6/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d9dGjq6aY3cN","colab":{}},"source":["# 내 노트북이 아닌, 전산실 컴퓨터의 colab에서 돌렸으므로, 다시돌리려면 경로 수정할것!\n","sys.path.append(\"/content/drive/My Drive/Colab Notebooks/project\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MM1f9wE47hsv","colab":{}},"source":["from lrn import LRN #만든 모듈, class\n","from f1score import macro_f1score, weighted_f1score\n","from pool_helper import PoolHelper"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HKLMWqbuUBkf","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape, Lambda, Add\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D\n","from tensorflow.keras.layers import add\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger,Callback\n","from tensorflow.keras.regularizers import l1,l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209766281,"user_tz":-540,"elapsed":18858,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"cbiFovMgXTax","outputId":"208a2335-d394-45cc-b8fe-6cd22f9035e2","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["os.getcwd()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks/project'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Ix8wPCMWm-z","colab":{}},"source":["# Alexnet을 개조\n","# Data Augmentation은 컴퓨터 성능의 한계로 못하기 때문에 변형함.\n","\n","# 주의 !!!!기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!!!\n","\n","# data import\n","x_train = pd.read_csv(\"mydata/X_train.csv\",header=0,index_col=0)\n","x_valid = pd.read_csv(\"mydata/X_private_test.csv\",header=0,index_col=0)\n","x_test = pd.read_csv(\"mydata/X_public_test.csv\",header=0,index_col=0)\n","y_train = pd.read_csv(\"mydata/y_train.csv\",header=0,index_col=0)\n","y_valid = pd.read_csv(\"mydata/y_private_test.csv\",header=0,index_col=0)\n","y_test = pd.read_csv(\"mydata/y_public_test.csv\",header=0,index_col=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWHRjz5AnGBE","colab_type":"code","colab":{}},"source":["# data handling\n","x_train = np.array(x_train).reshape([-1,48,48,3]) \n","x_valid = np.array(x_valid).reshape([-1,48,48,3]) \n","x_test = np.array(x_test).reshape([-1,48,48,3]) \n","\n","y_train=to_categorical(y_train) # one hot encoding\n","y_valid=to_categorical(y_valid)\n","y_test=to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u4J2YJEXb4H0","colab":{}},"source":["# data handling\n","size = 64 #적당한 크기로 잡음.\n","x_train = np.array(x_train).reshape([-1,48,48,3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PzT0Hoc0WnK3","colab":{}},"source":["x_train_zoom = np.zeros([x_train.shape[0],size,size,3],dtype=\"float32\")\n","\n","for i in range(x_train.shape[0]):\n","    x_train_zoom[i,:] = cv2.resize(x_train[i,:].astype('uint8'), (size, size),\n","                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xSE3FHaZnMzw","colab_type":"code","colab":{}},"source":["x_train = x_train / 255 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N-W1s7KpWnee","colab":{}},"source":["x_valid = np.array(x_valid).reshape([-1,48,48,3])\n","x_valid_zoom = np.zeros([x_valid.shape[0],size,size,3],dtype=\"float32\")\n","for i in range(x_valid.shape[0]):\n","    x_valid_zoom[i,:] = cv2.resize(x_valid[i,:].astype('uint8'), (size, size),\n","                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOgYraUQnNFx","colab_type":"code","colab":{}},"source":[" x_valid = x_valid / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zBIQHqomb--R","colab":{}},"source":["x_test = np.array(x_test).reshape([-1,48,48,3])\n","x_test_zoom = np.zeros([x_test.shape[0],size,size,3],dtype=\"float32\")\n","for i in range(x_test.shape[0]):\n","    x_test_zoom[i,:] = cv2.resize(x_test[i,:].astype('uint8'), (size, size),\n","                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9r1wRmn0nNb4","colab_type":"code","colab":{}},"source":["x_test = x_test / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kfIhYMYhDBPz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zNLG_Q4LCRR-","colab":{}},"source":["datagen = ImageDataGenerator(\n","    featurewise_center=False,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    zoom_range=[0.9,1.0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wu67A9xLCRSA","colab":{}},"source":["datagen_val = ImageDataGenerator()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bWvLB1sdCRSC","colab":{}},"source":["xy_valid_zoom_gen = datagen_val.flow(x_valid_zoom,y_valid,batch_size=64)\n","xy_valid_gen = datagen_val.flow(x_valid,y_valid,batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oz329xwsDBN8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Kiu3oJRIagkw"},"source":["## 1. My Alexnet"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5UromlgD5OEz"},"source":["#### 1) Size = 64"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bSApK_jeb_Lo","colab":{}},"source":["# 다음의 절차로 모형을 개조한다.\n","\n","# 1. 227의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n","# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n","# 3. 다음과 같이 모형을 재구성한다.\n","\n","# convolution layer\n","# 입력 : 64x64x1\n","# 첫번째 층 : 5x5 필터 24장, strides = 2 -> maxpooling 3x3 , stirdes = 2   ===> 14 x 14 x 24 feature map\n","# 두번째 층 : 3x3 필터 64장, strides = 1, padding = \"same\"                 ===> 14 x 14 x 64 feature map\n","# 세번째 층 : 3x3 필터 96장, strides = 1                                   ===> 12 x 12 x 96 feature map\n","# 네번째 층 : 3x3 필터 96장, strides = 1, padding = \"same\"                 ===> 12 x 12 x 96 feature map\n","# 다섯째 층 : 3x3 필터 64장, strides = 1 -> maxpooling 3x3 , strides = 2   ===> 4 x 4 x 64 feature map\n","\n","# fc layer\n","# 여섯째 층 : 노드 256개, dropout = 0.5\n","# 일곱째 층 : 노드 256개, dropout = 0.5\n","# 여덟째 층 : 노드 7개\n","\n","\n","\n","def Alexnet(img_shape=(64, 64, 3), n_classes=7, l2_reg=0.,\n","\tweights=None):\n","\n","\t# Initialize model\n","\talexnet = Sequential()\n","\n","\t# Layer 1\n","\talexnet.add(Conv2D(24, (5, 5), input_shape=img_shape, strides=2,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer1_LRN'))\n","\talexnet.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","\n","\t# Layer 2\n","\talexnet.add(Conv2D(64, (3, 3), padding='same',strides=1,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer2_LRN'))\n","\n","\t# Layer 3\n","\talexnet.add(Conv2D(96, (3, 3),  strides=1,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer3_LRN'))\n","\n","\t# Layer 4\n","\talexnet.add(Conv2D(96, (3, 3), padding='same'))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer4_LRN'))\n","\n","\t# Layer 5\n","\talexnet.add(Conv2D(64, (3, 3)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer5_LRN'))\n","\talexnet.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","\n","\t# Layer 6\n","\talexnet.add(Flatten())\n","\talexnet.add(Dense(256,kernel_regularizer=l2(l2_reg)))\n","\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(Dropout(0.5))\n","\n","\t# Layer 7\n","\talexnet.add(Dense(256,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(Dropout(0.5))\n","\n","\t# Layer 8\n","\talexnet.add(Dense(n_classes))\n","\talexnet.add(Activation('softmax'))\n","\n","\tif weights is not None:\n","\t\talexnet.load_weights(weights)\n","\n","\treturn alexnet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6BGhZH2FcL4S","colab":{}},"source":["#내 데이터 맞춤형 모형\n","model = Alexnet(img_shape=(64, 64, 3), n_classes=7, l2_reg=0.,weights=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209837418,"user_tz":-540,"elapsed":89933,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"TKsFtx5-b_PS","outputId":"e1dbc28e-d8c2-4340-b7d8-f2030e972b0a","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.summary()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 30, 30, 24)        1824      \n","_________________________________________________________________\n","activation (Activation)      (None, 30, 30, 24)        0         \n","_________________________________________________________________\n","layer1_LRN (LRN)             (None, 30, 30, 24)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 24)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 64)        13888     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","layer2_LRN (LRN)             (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 12, 12, 96)        55392     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 12, 12, 96)        0         \n","_________________________________________________________________\n","layer3_LRN (LRN)             (None, 12, 12, 96)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 12, 12, 96)        83040     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 12, 12, 96)        0         \n","_________________________________________________________________\n","layer4_LRN (LRN)             (None, 12, 12, 96)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 10, 10, 64)        55360     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","layer5_LRN (LRN)             (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1024)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               262400    \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 256)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 256)               0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 1799      \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 7)                 0         \n","=================================================================\n","Total params: 539,495\n","Trainable params: 539,495\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ipySpUqSb_TI","colab":{}},"source":["# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n","model.compile(optimizer='Adam', loss='categorical_crossentropy',\n","              metrics=['accuracy',macro_f1score,weighted_f1score])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SSlrXTG57Ro2","colab":{}},"source":["early_stopping = EarlyStopping(monitor='val_loss',patience=4,verbose=1,mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1592209868189,"user_tz":-540,"elapsed":120685,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"xCrOgpYza35L","outputId":"705647e8-d933-4973-8117-11129ef4ef90","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["# early stopping \n","history = model.fit(datagen.flow(x_train_zoom,y_train,batch_size=64), steps_per_epoch=len(x_train)/64, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","271/448 [=================>............] - ETA: 13s - loss: 1.8275 - accuracy: 0.2467 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-86185688a275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_zoom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mxy_valid_zoom_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_zoom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tx4jkpqMagld","scrolled":true,"colab":{}},"source":["_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=64)\n","print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjhHFRuM0FTY","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AZulQOln5OFK"},"source":["#### 2) Size = 48"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"awn16_7N5OFM","colab":{}},"source":["# 다음의 절차로 모형을 개조한다.\n","\n","# 1. 227의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n","# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n","# 3. 다음과 같이 모형을 재구성한다.\n","\n","# convolution layer\n","# 입력 : 64x64x1\n","# 첫번째 층 : 5x5 필터 24장, strides = 2 -> maxpooling 3x3 , stirdes = 2   ===> 10 x 10 x 24 feature map\n","# 두번째 층 : 3x3 필터 64장, strides = 1, padding = \"same\"                 ===> 14 x 14 x 64 feature map\n","# 세번째 층 : 3x3 필터 96장, strides = 1                                   ===> 12 x 12 x 96 feature map\n","# 네번째 층 : 3x3 필터 96장, strides = 1, padding = \"same\"                 ===> 12 x 12 x 96 feature map\n","# 다섯째 층 : 3x3 필터 64장, strides = 1 -> maxpooling 3x3 , strides = 2   ===> 4 x 4 x 64 feature map\n","\n","# fc layer\n","# 여섯째 층 : 노드 256개, dropout = 0.5\n","# 일곱째 층 : 노드 256개, dropout = 0.5\n","# 여덟째 층 : 노드 7개\n","\n","\n","\n","def Alexnet(img_shape=(48, 48, 3), n_classes=7, l2_reg=0., weights=None):\n","\n","\t# Initialize model\n","\talexnet = Sequential()\n","\n","\n","\t# Layer 1\n","\talexnet.add(Conv2D(24, (5, 5), input_shape=img_shape, strides=2,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer1_LRN'))\n","\talexnet.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","\n","\t# Layer 2\n","\talexnet.add(Conv2D(64, (3, 3), padding='same',strides=1,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer2_LRN'))\n","\n","\t# Layer 3\n","\talexnet.add(Conv2D(96, (3, 3),  strides=1,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer3_LRN'))\n","\n","\t# Layer 4\n","\talexnet.add(Conv2D(96, (3, 3), padding='same'))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer4_LRN'))\n","\n","\t# Layer 5\n","\talexnet.add(Conv2D(64, (3, 3)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(LRN(name='layer5_LRN'))\n","\talexnet.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","\n","\t# Layer 6\n","\talexnet.add(Flatten())\n","\talexnet.add(Dense(256,kernel_regularizer=l2(l2_reg)))\n","\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(Dropout(0.5))\n","\n","\t# Layer 7\n","\talexnet.add(Dense(256,kernel_regularizer=l2(l2_reg)))\n","\talexnet.add(Activation('relu'))\n","\talexnet.add(Dropout(0.5))\n","\n","\t# Layer 8\n","\talexnet.add(Dense(n_classes))\n","\talexnet.add(Activation('softmax'))\n","\n","\tif weights is not None:\n","\t\talexnet.load_weights(weights)\n","\n","\treturn alexnet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IpvNZ_S46glS","colab":{}},"source":["#내 데이터 맞춤형 모형\n","model = Alexnet(img_shape=(48, 48, 3), n_classes=7, l2_reg=0.,weights=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MP0_eJO16kYn","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fgvI2ih45OFP","colab":{}},"source":["# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n","model.compile(optimizer='Adam', loss='categorical_crossentropy',\n","              metrics=['accuracy',macro_f1score,weighted_f1score])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GtKWoWXi5OFU","colab":{}},"source":["early_stopping = EarlyStopping(monitor='val_loss',patience=4,verbose=1,mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WjKY-EtF5OFX","colab":{}},"source":["# early stopping \n","history = model.fit(datagen.flow(x_train_zoom,y_train,batch_size=64), steps_per_epoch=len(x_train)/64, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gww6lUzt5OFa","colab":{}},"source":["_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=64)\n","print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQwW2r-CzlR2","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wk20gexzlT1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5JHzTblzlXy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mhbphHbX9dXr"},"source":["# 2. VGG. For Size = 64,\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QehTu2Sfzzep"},"source":["### 1) My VGG11 (Pretraining)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jzefvtA5zzeq","colab":{}},"source":["# 논문에서 VGG19 의 FC층은 VGG11로 pretraining하여 얻은 초기치로 설정하였음.\n","# 기존의 VGG11을 개조\n","# Data Augmentation은 컴퓨터 성능의 한계로 못하기 때문에 변형함.\n","\n","# 주의 !!!!기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!!!\n","\n","# 다음의 절차로 모형을 개조한다.\n","\n","# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n","# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n","# 3. Conv의 filter는 1/8로 줄인다.\n","# 4. 다음과 같이 모형을 재구성한다.\n","# 5. 위의 내용은 앞으로 비교될 모형에서도 공통적으로 작용한다.\n","\n","def VGG11(input_shape=(64,64,3), classes=7,include_top=True,pooling=None, weights = None):\n","\n","    img_input = Input(shape=input_shape)\n","\n","    # Block 1\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","\n","    if include_top:\n","        # Classification block\n","        x = Flatten(name='flatten')(x)\n","        x = Dense(256, activation='relu',name='fc1')(x)\n","        x = Dense(256, activation='relu', name='fc2')(x)\n","        output = Dense(classes, activation='softmax', name='predictions')(x)\n","    else:\n","        if pooling == 'avg':\n","            output = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            output = GlobalMaxPooling2D()(x)\n","\n","    # Create model.\n","    model = Model(img_input, output, name='Vgg11_Pretraining')\n","\n","    if weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c-BegNkOzzes","colab":{}},"source":["#내 데이터 맞춤형 모형\n","model = VGG11(input_shape=(64, 64, 3), classes=7, include_top=True,pooling=None, weights = None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209875661,"user_tz":-540,"elapsed":822,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"outputId":"df7b797f-584f-4761-d347-612d84b0880c","scrolled":true,"id":"vj3sGq18zzeu","colab":{"base_uri":"https://localhost:8080/","height":809}},"source":["model.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"Vgg11_Pretraining\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 64, 64, 8)         224       \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 32, 32, 8)         0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 32, 32, 16)        1168      \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 16, 16, 32)        4640      \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 16, 16, 32)        9248      \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 8, 8, 32)          0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 8, 8, 64)          18496     \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 8, 8, 64)          36928     \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 4, 4, 64)          36928     \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 256)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 256)               65792     \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 256)               65792     \n","_________________________________________________________________\n","predictions (Dense)          (None, 7)                 1799      \n","=================================================================\n","Total params: 277,943\n","Trainable params: 277,943\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iHzLu9gEzzew","colab":{}},"source":["# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n","model.compile(optimizer='Adam', loss='categorical_crossentropy',\n","              metrics=['accuracy',macro_f1score,weighted_f1score])\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',patience = 4 , verbose=1,mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1592209880714,"user_tz":-540,"elapsed":4122,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"id":"kDIuXikrb_R2","outputId":"2b5779e8-8a8e-461b-c55a-a4ee0f3434a9","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["# early stopping \n","history = model.fit(datagen.flow(x_train_zoom,y_train,batch_size=64), steps_per_epoch=len(x_train)/64, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":31,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"," 29/448 [>.............................] - ETA: 30s - loss: 1.8406 - accuracy: 0.2629 - macro_f1score: 0.0011 - weighted_f1score: 2.3091e-04"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-86185688a275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_zoom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mxy_valid_zoom_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_zoom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5U1VVM-0FF_x","colab":{}},"source":["_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=64)\n","print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MXEL-UE0t1e","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-aQSDtcLFF_z","colab":{}},"source":["# 한층당 W 와 b , 2개씩 있으므로 11개층이라면 22개의 모수 벡터 및 행렬이 출력된다.\n","W = model.get_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-90tcTlCFGAC"},"source":["### 2) My VGG16 (Pretrained)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kcS0I-HoZVk3","colab":{}},"source":["# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n","# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n","# 3. Conv의 filter는 1/8로 줄인다.\n","# 4. 다음과 같이 모형을 재구성한다.\n","# 5. 위의 내용은 앞으로 비교될 모형에서도 공통적으로 작용한다.\n","\n","\n","def VGG16(input_shape=(64,64,3), classes=7,include_top=True,pooling=None, weights = None):\n","\n","    img_input = Input(shape=input_shape)\n","\n","    # Block 1\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","\n","    if include_top:\n","        # Classification block\n","        x = Flatten(name='flatten')(x)\n","        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n","        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n","        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n","    else:\n","        if pooling == 'avg':\n","            output = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            output = GlobalMaxPooling2D()(x)\n","\n","    # Create model.\n","    model = Model(img_input, output, name='vgg16')\n","\n","    # Load weights.\n","    # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n","    if weights == 'imagenet':\n","        if include_top:\n","            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n","                WEIGHTS_PATH,cache_subdir='models',file_hash='cbe5617147190e668d6c5d5026f83318')\n","        else:\n","            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                WEIGHTS_PATH_NO_TOP,cache_subdir='models',file_hash='253f8cb515780f3b799900260a226db6')\n","\n","        model.load_weights(weights_path) #경로에 있는 초기치 weights가져오기\n","\n","    elif weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2wcZln93ZVsF","colab":{}},"source":["model = VGG16(input_shape=(64, 64, 3), classes=7, include_top=True,pooling=None, weights = None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"16xkrOFIZVzK","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R5SxMkHcZV5t","colab":{}},"source":["model.compile(optimizer='Adam', loss='categorical_crossentropy',\n","              metrics=['accuracy',macro_f1score,weighted_f1score])\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',patience = 4 , verbose=1,mode='min')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d64FCl-pZpIN","scrolled":true,"colab":{}},"source":["# early stopping \n","history = model.fit(datagen.flow(x_train_zoom,y_train,batch_size=64), steps_per_epoch=len(x_train)/64, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LehU2TtdZpGb","scrolled":true,"colab":{}},"source":["_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=64)\n","print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ucq9bZlL0zAe","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i_44ReAz9dZe"},"source":["## 3. For Size =48,\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iHJl3jbr9dZf"},"source":["### 1) My VGG11 (Pretraining)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lbmiiqjr9dZg","colab":{}},"source":["# 오리지널 데이터에 대해 다루어본다.\n","\n","def VGG11(input_shape=(48,48,3), classes=7,include_top=True,pooling=None, weights = None):\n","\n","    img_input = Input(shape=input_shape)\n","\n","    # Block 1\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = MaxPooling2D((3, 3), strides=(3, 3), name='block5_pool')(x)\n","    # 데이터 size = 48로 하므로써, 전체를 maxpooling 하는 것으로 바꿈.\n","\n","    if include_top:\n","        # Classification block\n","        x = Flatten(name='flatten')(x)\n","        x = Dense(256, activation='relu',name='fc1')(x)\n","        x = Dense(256, activation='relu', name='fc2')(x)\n","        output = Dense(classes, activation='softmax', name='predictions')(x)\n","    else:\n","        if pooling == 'avg':\n","            output = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            output = GlobalMaxPooling2D()(x)\n","\n","    # Create model.\n","    model = Model(img_input, output, name='Vgg11_Pretraining')\n","\n","    if weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QiYnsfxH9dZi","colab":{}},"source":["#내 데이터 맞춤형 모형\n","model = VGG11(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4PuUC6OM9dZk","scrolled":true,"colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6bVw85Z49dZm","colab":{}},"source":["# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n","model.compile(optimizer='Adam', loss='categorical_crossentropy',\n","              metrics=['accuracy',macro_f1score,weighted_f1score])\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',patience = 4 , verbose=1,mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UmsKJ9kt9dZq","scrolled":true,"colab":{}},"source":["# early stopping \n","history = model.fit(datagen.flow(x_train_zoom,y_train,batch_size=64), steps_per_epoch=len(x_train)/64, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s1MHxxJW9dZs","colab":{}},"source":["_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=64)\n","print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6es-1HPc1PQ5","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-72M2H7K9dZv","colab":{}},"source":["# 한층당 W 와 b , 2개씩 있으므로 11개층이라면 22개의 모수 벡터 및 행렬이 출력된다.\n","W = model.get_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BsRCepsp9daJ"},"source":["### 2) My VGG16 (Pretrained)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IN4KG4tE9daK","colab":{}},"source":["def VGG16(input_shape=(48,48,3), classes=7,include_top=True,pooling=None, weights = None):\n","\n","    img_input = Input(shape=input_shape)\n","\n","    # Block 1\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","    # 데이터 size = 48로 하므로써, 전체를 maxpooling 하는 것으로 바꿈.\n","\n","    if include_top:\n","        # Classification block\n","        x = Flatten(name='flatten')(x)\n","        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n","        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n","        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n","    else:\n","        if pooling == 'avg':\n","            output = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            output = GlobalMaxPooling2D()(x)\n","\n","    # Create model.\n","    model = Model(img_input, output, name='vgg16')\n","\n","    # Load weights.\n","    # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n","    if weights == 'imagenet':\n","        if include_top:\n","            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n","                WEIGHTS_PATH,cache_subdir='models',file_hash='cbe5617147190e668d6c5d5026f83318')\n","        else:\n","            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                WEIGHTS_PATH_NO_TOP,cache_subdir='models',file_hash='253f8cb515780f3b799900260a226db6')\n","\n","        model.load_weights(weights_path) #경로에 있는 초기치 weights가져오기\n","\n","    elif weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6JNNWkMu9daM","colab":{}},"source":["model = VGG16(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zpjWzJHC9daN","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rr6H7kKq9daQ","colab":{}},"source":["model.compile(optimizer='Adam', loss='categorical_crossentropy',\n","              metrics=['accuracy',macro_f1score,weighted_f1score])\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',patience = 4 , verbose=1,mode='min')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"747u68c59daT","colab":{}},"source":["# early stopping \n","history = model.fit(datagen.flow(x_train_zoom,y_train,batch_size=64), steps_per_epoch=len(x_train)/64, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6APhKqEc9daW","colab":{}},"source":["_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=64)\n","print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"joyAz0r21UZh","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ1lUmhfzlad","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPC81Vea2N-A","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4kZwp9zaD6_o","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4RldjwO4M8_o","colab":{}},"source":["# GoogLeNet은 input이 3개, output이 3개이므로 imagedatagenerator 사용방법이 다소 다르다.\n","# model.fit에 다중 input으로 들어갈 함수를 개인이 만들어서 사용해야 하며, 그 함수는 아래와 같다. \n","# 매우 간단하다.\n","\n","#1. train data\n","\n","datagen = ImageDataGenerator(featurewise_center=False,\n","                              featurewise_std_normalization=False,\n","                              rotation_range=10,\n","                              width_shift_range=0.1,\n","                              height_shift_range=0.1,\n","                              horizontal_flip=True,\n","                              zoom_range=[0.9,1.0])\n","\n","\n","def generate_train_for_three(X , Y):\n","\n","      batches_xy = datagen.flow(X , Y, batch_size=64)\n","\n","      while True:\n","\n","            batch_xy = batches_xy.next()\n","            yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yOMw3HckS2s7","colab":{}},"source":["# 2. valid data\n","\n","datagen_val = ImageDataGenerator()\n","\n","def generate_valid_for_three(X , Y):\n","\n","      batches_xy = datagen_val.flow(X , Y, batch_size=64)\n","\n","      while True:\n","\n","            batch_xy = batches_xy.next()\n","            yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ljcicMaq2NMy"},"source":["## 2. My GoogLeNet"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eJwwvvImGO2X"},"source":["### 1) Size = 64"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4AfCRuFx2NM1","colab":{}},"source":["# 기존의 GoogLeNet 개조\n","\n","# Data Augmentation은 컴퓨터 성능의 한계로 못하기 때문에 변형함.\n","\n","# 주의 !!!!기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!!!\n","\n","# 다음의 절차로 모형을 개조한다.\n","\n","# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n","# 2. stride 2개, pool_size 1개를 변형해서, 최대한 전체적인 모형의 변화를 줄였다.\n","# 3. 다음과 같이 모형을 재구성한다.\n","\n","\n","def my_googlenet(input_shape=(64,64,3), classes=7 , weights_path = None ):\n","\n","    input = Input(input_shape)\n","\n","    input_pad = ZeroPadding2D(padding=(3, 3))(input)\n","    conv1_7x7_s2 = Conv2D(8, (7,7), strides=(1,1), padding='valid', activation='relu', name='conv1/7x7_s2', kernel_regularizer=l2(0.0002))(input_pad)\n","    # 위에서 stride 2 -> 1로 바꿈.\n","    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n","    pool1_helper = PoolHelper()(conv1_zero_pad)\n","    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool1/3x3_s2')(pool1_helper)\n","    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n","\n","    conv2_3x3_reduce = Conv2D(8, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_regularizer=l2(0.0002))(pool1_norm1)\n","    conv2_3x3 = Conv2D(24, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_regularizer=l2(0.0002))(conv2_3x3_reduce)\n","    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n","    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n","    pool2_helper = PoolHelper()(conv2_zero_pad)\n","    pool2_3x3_s2 = MaxPooling2D(pool_size=(6,6), strides=(1,1), padding='valid', name='pool2/3x3_s2')(pool2_helper)\n","    # 위에서 strdie 2 -> 1로 바꿈. , pool_size 3 -> 6 으로 바꿈.  /// 여기까지 완료하면 r x c = 28 x 28 이 됨.\n","\n","    inception_3a_1x1 = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n","    inception_3a_3x3_reduce = Conv2D(12, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n","    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n","    inception_3a_3x3 = Conv2D(16, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_regularizer=l2(0.0002))(inception_3a_3x3_pad)\n","    inception_3a_5x5_reduce = Conv2D(2, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n","    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n","    inception_3a_5x5 = Conv2D(4, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_regularizer=l2(0.0002))(inception_3a_5x5_pad)\n","    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n","    inception_3a_pool_proj = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_regularizer=l2(0.0002))(inception_3a_pool)\n","    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n","\n","    inception_3b_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_regularizer=l2(0.0002))(inception_3a_output)\n","    inception_3b_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n","    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n","    inception_3b_3x3 = Conv2D(24, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_regularizer=l2(0.0002))(inception_3b_3x3_pad)\n","    inception_3b_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n","    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n","    inception_3b_5x5 = Conv2D(12, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_regularizer=l2(0.0002))(inception_3b_5x5_pad)\n","    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n","    inception_3b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_regularizer=l2(0.0002))(inception_3b_pool)\n","    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n","\n","    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n","    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n","    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool3/3x3_s2')(pool3_helper)\n","\n","    inception_4a_1x1 = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n","    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n","    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n","    inception_4a_3x3 = Conv2D(26, (3,3), padding='valid', activation='relu', name='inception_4a/3x3' ,kernel_regularizer=l2(0.0002))(inception_4a_3x3_pad)\n","    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n","    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n","    inception_4a_5x5 = Conv2D(6, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_regularizer=l2(0.0002))(inception_4a_5x5_pad)\n","    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n","    inception_4a_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_regularizer=l2(0.0002))(inception_4a_pool)\n","    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n","\n","    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n","    loss1_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_regularizer=l2(0.0002))(loss1_ave_pool)\n","    loss1_flat = Flatten()(loss1_conv)\n","    loss1_fc = Dense(64, activation='relu', name='loss1/fc', kernel_regularizer=l2(0.0002))(loss1_flat)\n","    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n","    loss1_classifier = Dense(classes, name='loss1/classifier', kernel_regularizer=l2(0.0002))(loss1_drop_fc)\n","    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n","\n","    inception_4b_1x1 = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_regularizer=l2(0.0002))(inception_4a_output)\n","    inception_4b_3x3_reduce = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n","    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n","    inception_4b_3x3 = Conv2D(28, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_regularizer=l2(0.0002))(inception_4b_3x3_pad)\n","    inception_4b_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n","    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n","    inception_4b_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_regularizer=l2(0.0002))(inception_4b_5x5_pad)\n","    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n","    inception_4b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_regularizer=l2(0.0002))(inception_4b_pool)\n","    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n","\n","    inception_4c_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_regularizer=l2(0.0002))(inception_4b_output)\n","    inception_4c_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n","    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n","    inception_4c_3x3 = Conv2D(32, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_regularizer=l2(0.0002))(inception_4c_3x3_pad)\n","    inception_4c_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n","    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n","    inception_4c_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_regularizer=l2(0.0002))(inception_4c_5x5_pad)\n","    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n","    inception_4c_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_regularizer=l2(0.0002))(inception_4c_pool)\n","    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n","\n","    inception_4d_1x1 = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_regularizer=l2(0.0002))(inception_4c_output)\n","    inception_4d_3x3_reduce = Conv2D(18, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n","    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n","    inception_4d_3x3 = Conv2D(36, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_regularizer=l2(0.0002))(inception_4d_3x3_pad)\n","    inception_4d_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n","    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n","    inception_4d_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_regularizer=l2(0.0002))(inception_4d_5x5_pad)\n","    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n","    inception_4d_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_regularizer=l2(0.0002))(inception_4d_pool)\n","    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n","\n","    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n","    loss2_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_regularizer=l2(0.0002))(loss2_ave_pool)\n","    loss2_flat = Flatten()(loss2_conv)\n","    loss2_fc = Dense(8, activation='relu', name='loss2/fc', kernel_regularizer=l2(0.0002))(loss2_flat)\n","    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n","    loss2_classifier = Dense(classes, name='loss2/classifier', kernel_regularizer=l2(0.0002))(loss2_drop_fc)\n","    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n","\n","    inception_4e_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_regularizer=l2(0.0002))(inception_4d_output)\n","    inception_4e_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n","    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n","    inception_4e_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_regularizer=l2(0.0002))(inception_4e_3x3_pad)\n","    inception_4e_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n","    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n","    inception_4e_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_regularizer=l2(0.0002))(inception_4e_5x5_pad)\n","    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n","    inception_4e_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_regularizer=l2(0.0002))(inception_4e_pool)\n","    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n","\n","    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n","    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n","    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool4/3x3_s2')(pool4_helper)\n","\n","    inception_5a_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n","    inception_5a_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n","    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n","    inception_5a_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_regularizer=l2(0.0002))(inception_5a_3x3_pad)\n","    inception_5a_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n","    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n","    inception_5a_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_regularizer=l2(0.0002))(inception_5a_5x5_pad)\n","    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n","    inception_5a_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_regularizer=l2(0.0002))(inception_5a_pool)\n","    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n","\n","    inception_5b_1x1 = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_regularizer=l2(0.0002))(inception_5a_output)\n","    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n","    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n","    inception_5b_3x3 = Conv2D(48, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_regularizer=l2(0.0002))(inception_5b_3x3_pad)\n","    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n","    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n","    inception_5b_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_regularizer=l2(0.0002))(inception_5b_5x5_pad)\n","    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n","    inception_5b_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_regularizer=l2(0.0002))(inception_5b_pool)\n","    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n","\n","    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output)\n","    loss3_flat = Flatten()(pool5_7x7_s1)\n","    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n","    loss3_classifier = Dense(classes, name='loss3/classifier', kernel_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n","    loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n","\n","    googlenet = Model(inputs=input, outputs=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n","\n","\n","    if weights_path:\n","        googlenet.load_weights(weights_path)\n","\n","    # if tf.keras.backend.backend() == 'tensorflow':\n","    #     # 우리는 tf.keras를 쓰므로, 이상황은 늘 True.\n","    #     # 또한, 아래의 코드도 시행할 필요가 없다.\n","    #     # 혹시모를 , 나중의 상황에 대비해 코드만 남겨놓는다.\n","    #\n","    #     ops = []\n","    #     for layer in googlenet.layers:\n","    #         if layer.__class__.__name__ == 'Conv2D': # layer의 class의 이름이 'conv2d'이면 ~\n","    #             original_w = K.get_value(layer.kernel)\n","    #             converted_w = convert_kernel(original_w)\n","    #             ops.append(tf.assign(layer.kernel, converted_w).op)\n","    #     K.get_session().run(ops)\n","\n","    return googlenet\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v6RFGHvY2NM3","colab":{}},"source":["#내 데이터 맞춤형 모형\n","\n","model = my_googlenet(input_shape=(64, 64, 3), classes=7, weights_path = None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1592209905216,"user_tz":-540,"elapsed":544,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"outputId":"e0106d6f-3e85-48c7-e591-38f1c0cb54bf","scrolled":true,"id":"rQKcmnGh2NM5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.summary()"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/7x7_s2 (Conv2D)           (None, 64, 64, 8)    1184        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 8)    0           conv1/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","pool_helper (PoolHelper)        (None, 65, 65, 8)    0           zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","pool1/3x3_s2 (MaxPooling2D)     (None, 32, 32, 8)    0           pool_helper[0][0]                \n","__________________________________________________________________________________________________\n","pool1/norm1 (LRN)               (None, 32, 32, 8)    0           pool1/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","conv2/3x3_reduce (Conv2D)       (None, 32, 32, 8)    72          pool1/norm1[0][0]                \n","__________________________________________________________________________________________________\n","conv2/3x3 (Conv2D)              (None, 32, 32, 24)   1752        conv2/3x3_reduce[0][0]           \n","__________________________________________________________________________________________________\n","conv2/norm2 (LRN)               (None, 32, 32, 24)   0           conv2/3x3[0][0]                  \n","__________________________________________________________________________________________________\n","zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 24)   0           conv2/norm2[0][0]                \n","__________________________________________________________________________________________________\n","pool_helper_1 (PoolHelper)      (None, 33, 33, 24)   0           zero_padding2d_2[0][0]           \n","__________________________________________________________________________________________________\n","pool2/3x3_s2 (MaxPooling2D)     (None, 28, 28, 24)   0           pool_helper_1[0][0]              \n","__________________________________________________________________________________________________\n","inception_3a/3x3_reduce (Conv2D (None, 28, 28, 12)   300         pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/5x5_reduce (Conv2D (None, 28, 28, 2)    50          pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_3 (ZeroPadding2D (None, 30, 30, 12)   0           inception_3a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_4 (ZeroPadding2D (None, 32, 32, 2)    0           inception_3a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_3a/pool (MaxPooling2D (None, 28, 28, 24)   0           pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/1x1 (Conv2D)       (None, 28, 28, 8)    200         pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/3x3 (Conv2D)       (None, 28, 28, 16)   1744        zero_padding2d_3[0][0]           \n","__________________________________________________________________________________________________\n","inception_3a/5x5 (Conv2D)       (None, 28, 28, 4)    204         zero_padding2d_4[0][0]           \n","__________________________________________________________________________________________________\n","inception_3a/pool_proj (Conv2D) (None, 28, 28, 4)    100         inception_3a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_3a/output (Concatenat (None, 28, 28, 32)   0           inception_3a/1x1[0][0]           \n","                                                                 inception_3a/3x3[0][0]           \n","                                                                 inception_3a/5x5[0][0]           \n","                                                                 inception_3a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_3b/3x3_reduce (Conv2D (None, 28, 28, 16)   528         inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/5x5_reduce (Conv2D (None, 28, 28, 4)    132         inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_5 (ZeroPadding2D (None, 30, 30, 16)   0           inception_3b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_6 (ZeroPadding2D (None, 32, 32, 4)    0           inception_3b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_3b/pool (MaxPooling2D (None, 28, 28, 32)   0           inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/1x1 (Conv2D)       (None, 28, 28, 16)   528         inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/3x3 (Conv2D)       (None, 28, 28, 24)   3480        zero_padding2d_5[0][0]           \n","__________________________________________________________________________________________________\n","inception_3b/5x5 (Conv2D)       (None, 28, 28, 12)   1212        zero_padding2d_6[0][0]           \n","__________________________________________________________________________________________________\n","inception_3b/pool_proj (Conv2D) (None, 28, 28, 8)    264         inception_3b/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_3b/output (Concatenat (None, 28, 28, 60)   0           inception_3b/1x1[0][0]           \n","                                                                 inception_3b/3x3[0][0]           \n","                                                                 inception_3b/5x5[0][0]           \n","                                                                 inception_3b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","zero_padding2d_7 (ZeroPadding2D (None, 30, 30, 60)   0           inception_3b/output[0][0]        \n","__________________________________________________________________________________________________\n","pool_helper_2 (PoolHelper)      (None, 29, 29, 60)   0           zero_padding2d_7[0][0]           \n","__________________________________________________________________________________________________\n","pool3/3x3_s2 (MaxPooling2D)     (None, 14, 14, 60)   0           pool_helper_2[0][0]              \n","__________________________________________________________________________________________________\n","inception_4a/3x3_reduce (Conv2D (None, 14, 14, 96)   5856        pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/5x5_reduce (Conv2D (None, 14, 14, 16)   976         pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_8 (ZeroPadding2D (None, 16, 16, 96)   0           inception_4a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_9 (ZeroPadding2D (None, 18, 18, 16)   0           inception_4a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4a/pool (MaxPooling2D (None, 14, 14, 60)   0           pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/1x1 (Conv2D)       (None, 14, 14, 24)   1464        pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/3x3 (Conv2D)       (None, 14, 14, 26)   22490       zero_padding2d_8[0][0]           \n","__________________________________________________________________________________________________\n","inception_4a/5x5 (Conv2D)       (None, 14, 14, 6)    2406        zero_padding2d_9[0][0]           \n","__________________________________________________________________________________________________\n","inception_4a/pool_proj (Conv2D) (None, 14, 14, 8)    488         inception_4a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4a/output (Concatenat (None, 14, 14, 64)   0           inception_4a/1x1[0][0]           \n","                                                                 inception_4a/3x3[0][0]           \n","                                                                 inception_4a/5x5[0][0]           \n","                                                                 inception_4a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4b/3x3_reduce (Conv2D (None, 14, 14, 14)   910         inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/5x5_reduce (Conv2D (None, 14, 14, 3)    195         inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_10 (ZeroPadding2 (None, 16, 16, 14)   0           inception_4b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 3)    0           inception_4b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4b/pool (MaxPooling2D (None, 14, 14, 64)   0           inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/1x1 (Conv2D)       (None, 14, 14, 20)   1300        inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/3x3 (Conv2D)       (None, 14, 14, 28)   3556        zero_padding2d_10[0][0]          \n","__________________________________________________________________________________________________\n","inception_4b/5x5 (Conv2D)       (None, 14, 14, 8)    608         zero_padding2d_11[0][0]          \n","__________________________________________________________________________________________________\n","inception_4b/pool_proj (Conv2D) (None, 14, 14, 8)    520         inception_4b/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4b/output (Concatenat (None, 14, 14, 64)   0           inception_4b/1x1[0][0]           \n","                                                                 inception_4b/3x3[0][0]           \n","                                                                 inception_4b/5x5[0][0]           \n","                                                                 inception_4b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4c/3x3_reduce (Conv2D (None, 14, 14, 16)   1040        inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/5x5_reduce (Conv2D (None, 14, 14, 3)    195         inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 16)   0           inception_4c/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 3)    0           inception_4c/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4c/pool (MaxPooling2D (None, 14, 14, 64)   0           inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/1x1 (Conv2D)       (None, 14, 14, 16)   1040        inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/3x3 (Conv2D)       (None, 14, 14, 32)   4640        zero_padding2d_12[0][0]          \n","__________________________________________________________________________________________________\n","inception_4c/5x5 (Conv2D)       (None, 14, 14, 8)    608         zero_padding2d_13[0][0]          \n","__________________________________________________________________________________________________\n","inception_4c/pool_proj (Conv2D) (None, 14, 14, 8)    520         inception_4c/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4c/output (Concatenat (None, 14, 14, 64)   0           inception_4c/1x1[0][0]           \n","                                                                 inception_4c/3x3[0][0]           \n","                                                                 inception_4c/5x5[0][0]           \n","                                                                 inception_4c/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4d/3x3_reduce (Conv2D (None, 14, 14, 18)   1170        inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/5x5_reduce (Conv2D (None, 14, 14, 4)    260         inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_14 (ZeroPadding2 (None, 16, 16, 18)   0           inception_4d/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_15 (ZeroPadding2 (None, 18, 18, 4)    0           inception_4d/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4d/pool (MaxPooling2D (None, 14, 14, 64)   0           inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/1x1 (Conv2D)       (None, 14, 14, 14)   910         inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/3x3 (Conv2D)       (None, 14, 14, 36)   5868        zero_padding2d_14[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/5x5 (Conv2D)       (None, 14, 14, 8)    808         zero_padding2d_15[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/pool_proj (Conv2D) (None, 14, 14, 8)    520         inception_4d/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/output (Concatenat (None, 14, 14, 66)   0           inception_4d/1x1[0][0]           \n","                                                                 inception_4d/3x3[0][0]           \n","                                                                 inception_4d/5x5[0][0]           \n","                                                                 inception_4d/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4e/3x3_reduce (Conv2D (None, 14, 14, 20)   1340        inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/5x5_reduce (Conv2D (None, 14, 14, 4)    268         inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_16 (ZeroPadding2 (None, 16, 16, 20)   0           inception_4e/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_17 (ZeroPadding2 (None, 18, 18, 4)    0           inception_4e/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4e/pool (MaxPooling2D (None, 14, 14, 66)   0           inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/1x1 (Conv2D)       (None, 14, 14, 32)   2144        inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/3x3 (Conv2D)       (None, 14, 14, 40)   7240        zero_padding2d_16[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/5x5 (Conv2D)       (None, 14, 14, 16)   1616        zero_padding2d_17[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/pool_proj (Conv2D) (None, 14, 14, 16)   1072        inception_4e/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/output (Concatenat (None, 14, 14, 104)  0           inception_4e/1x1[0][0]           \n","                                                                 inception_4e/3x3[0][0]           \n","                                                                 inception_4e/5x5[0][0]           \n","                                                                 inception_4e/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","zero_padding2d_18 (ZeroPadding2 (None, 16, 16, 104)  0           inception_4e/output[0][0]        \n","__________________________________________________________________________________________________\n","pool_helper_3 (PoolHelper)      (None, 15, 15, 104)  0           zero_padding2d_18[0][0]          \n","__________________________________________________________________________________________________\n","pool4/3x3_s2 (MaxPooling2D)     (None, 7, 7, 104)    0           pool_helper_3[0][0]              \n","__________________________________________________________________________________________________\n","inception_5a/3x3_reduce (Conv2D (None, 7, 7, 20)     2100        pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/5x5_reduce (Conv2D (None, 7, 7, 4)      420         pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_19 (ZeroPadding2 (None, 9, 9, 20)     0           inception_5a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_20 (ZeroPadding2 (None, 11, 11, 4)    0           inception_5a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_5a/pool (MaxPooling2D (None, 7, 7, 104)    0           pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/1x1 (Conv2D)       (None, 7, 7, 32)     3360        pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/3x3 (Conv2D)       (None, 7, 7, 40)     7240        zero_padding2d_19[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/5x5 (Conv2D)       (None, 7, 7, 16)     1616        zero_padding2d_20[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/pool_proj (Conv2D) (None, 7, 7, 16)     1680        inception_5a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/output (Concatenat (None, 7, 7, 104)    0           inception_5a/1x1[0][0]           \n","                                                                 inception_5a/3x3[0][0]           \n","                                                                 inception_5a/5x5[0][0]           \n","                                                                 inception_5a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_5b/3x3_reduce (Conv2D (None, 7, 7, 192)    20160       inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/5x5_reduce (Conv2D (None, 7, 7, 48)     5040        inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_21 (ZeroPadding2 (None, 9, 9, 192)    0           inception_5b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_22 (ZeroPadding2 (None, 11, 11, 48)   0           inception_5b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_5b/pool (MaxPooling2D (None, 7, 7, 104)    0           inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","loss1/ave_pool (AveragePooling2 (None, 4, 4, 64)     0           inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","loss2/ave_pool (AveragePooling2 (None, 4, 4, 66)     0           inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/1x1 (Conv2D)       (None, 7, 7, 48)     5040        inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/3x3 (Conv2D)       (None, 7, 7, 48)     82992       zero_padding2d_21[0][0]          \n","__________________________________________________________________________________________________\n","inception_5b/5x5 (Conv2D)       (None, 7, 7, 16)     19216       zero_padding2d_22[0][0]          \n","__________________________________________________________________________________________________\n","inception_5b/pool_proj (Conv2D) (None, 7, 7, 16)     1680        inception_5b/pool[0][0]          \n","__________________________________________________________________________________________________\n","loss1/conv (Conv2D)             (None, 4, 4, 16)     1040        loss1/ave_pool[0][0]             \n","__________________________________________________________________________________________________\n","loss2/conv (Conv2D)             (None, 4, 4, 16)     1072        loss2/ave_pool[0][0]             \n","__________________________________________________________________________________________________\n","inception_5b/output (Concatenat (None, 7, 7, 128)    0           inception_5b/1x1[0][0]           \n","                                                                 inception_5b/3x3[0][0]           \n","                                                                 inception_5b/5x5[0][0]           \n","                                                                 inception_5b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 256)          0           loss1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 256)          0           loss2/conv[0][0]                 \n","__________________________________________________________________________________________________\n","pool5/7x7_s2 (AveragePooling2D) (None, 1, 1, 128)    0           inception_5b/output[0][0]        \n","__________________________________________________________________________________________________\n","loss1/fc (Dense)                (None, 64)           16448       flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","loss2/fc (Dense)                (None, 8)            2056        flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 128)          0           pool5/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 64)           0           loss1/fc[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 8)            0           loss2/fc[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 128)          0           flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","loss1/classifier (Dense)        (None, 7)            455         dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","loss2/classifier (Dense)        (None, 7)            63          dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","loss3/classifier (Dense)        (None, 7)            903         dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 7)            0           loss1/classifier[0][0]           \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 7)            0           loss2/classifier[0][0]           \n","__________________________________________________________________________________________________\n","prob (Activation)               (None, 7)            0           loss3/classifier[0][0]           \n","==================================================================================================\n","Total params: 256,359\n","Trainable params: 256,359\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YFKcnlQ43jmM","colab":{}},"source":["# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n","model.compile(optimizer='Adam', loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n","              metrics=['accuracy',macro_f1score,weighted_f1score])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LE02g-aC2NNF","colab":{}},"source":["early_stopping = EarlyStopping(monitor = 'val_loss',patience = 4 , verbose=1,mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1592209921222,"user_tz":-540,"elapsed":11767,"user":{"displayName":"‍이동규[ 대학원석사과정재학 / 통계학과 ]","photoUrl":"","userId":"08134145419451519269"}},"outputId":"0162bff7-e601-4335-b4c9-b28c95ce896c","scrolled":true,"id":"0UXQ4RTo2NNH","colab":{"base_uri":"https://localhost:8080/","height":378}},"source":["history = model.fit(generate_train_for_three(x_train_zoom,y_train), steps_per_epoch=len(x_train)/64, validation_data= generate_valid_for_three(x_valid_zoom,y_valid), validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":39,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"," 36/448 [=>............................] - ETA: 33s - loss: 3.2719 - activation_8_loss: 1.9195 - activation_9_loss: 1.9324 - prob_loss: 1.8631 - activation_8_accuracy: 0.1931 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2322 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2626 - prob_macro_f1score: 2.6455e-04 - prob_weighted_f1score: 7.4405e-05"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-36304817b6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_train_for_three\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_zoom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgenerate_valid_for_three\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_zoom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_zoom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zn21Eq3PxULW","scrolled":false,"colab":{}},"source":["*_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,[y_test,y_test,y_test],batch_size=64)\n","print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JzFWtAA2wPW","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['prob_accuracy']\n","val_acc=history.history['val_prob_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ndm2YY1cGO23"},"source":["### 2) Size = 48"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d1VYw0zTGO23","colab":{}},"source":["# size=64의 googlenet과의 차이점은, AveragePooling2D size가 7에서 5로 바뀌었다는점이다.\n","\n","def my_googlenet(input_shape=(48,48,3), classes=7 , weights_path = None ):\n","\n","    input = Input(input_shape)\n","\n","    input_pad = ZeroPadding2D(padding=(3, 3))(input)\n","    conv1_7x7_s2 = Conv2D(8, (7,7), strides=(1,1), padding='valid', activation='relu', name='conv1/7x7_s2', kernel_regularizer=l2(0.0002))(input_pad)\n","    # 위에서 stride 2 -> 1로 바꿈.\n","    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n","    pool1_helper = PoolHelper()(conv1_zero_pad)\n","    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool1/3x3_s2')(pool1_helper)\n","    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n","\n","    conv2_3x3_reduce = Conv2D(8, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_regularizer=l2(0.0002))(pool1_norm1)\n","    conv2_3x3 = Conv2D(24, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_regularizer=l2(0.0002))(conv2_3x3_reduce)\n","    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n","    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n","    pool2_helper = PoolHelper()(conv2_zero_pad)\n","    pool2_3x3_s2 = MaxPooling2D(pool_size=(6,6), strides=(1,1), padding='valid', name='pool2/3x3_s2')(pool2_helper)\n","    # 위에서 strdie 2 -> 1로 바꿈. , pool_size 3 -> 6 으로 바꿈.  /// 여기까지 완료하면 r x c = 28 x 28 이 됨.\n","\n","    inception_3a_1x1 = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n","    inception_3a_3x3_reduce = Conv2D(12, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n","    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n","    inception_3a_3x3 = Conv2D(16, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_regularizer=l2(0.0002))(inception_3a_3x3_pad)\n","    inception_3a_5x5_reduce = Conv2D(2, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n","    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n","    inception_3a_5x5 = Conv2D(4, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_regularizer=l2(0.0002))(inception_3a_5x5_pad)\n","    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n","    inception_3a_pool_proj = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_regularizer=l2(0.0002))(inception_3a_pool)\n","    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n","\n","    inception_3b_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_regularizer=l2(0.0002))(inception_3a_output)\n","    inception_3b_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n","    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n","    inception_3b_3x3 = Conv2D(24, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_regularizer=l2(0.0002))(inception_3b_3x3_pad)\n","    inception_3b_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n","    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n","    inception_3b_5x5 = Conv2D(12, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_regularizer=l2(0.0002))(inception_3b_5x5_pad)\n","    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n","    inception_3b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_regularizer=l2(0.0002))(inception_3b_pool)\n","    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n","\n","    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n","    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n","    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool3/3x3_s2')(pool3_helper)\n","\n","    inception_4a_1x1 = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n","    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n","    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n","    inception_4a_3x3 = Conv2D(26, (3,3), padding='valid', activation='relu', name='inception_4a/3x3' ,kernel_regularizer=l2(0.0002))(inception_4a_3x3_pad)\n","    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n","    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n","    inception_4a_5x5 = Conv2D(6, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_regularizer=l2(0.0002))(inception_4a_5x5_pad)\n","    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n","    inception_4a_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_regularizer=l2(0.0002))(inception_4a_pool)\n","    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n","\n","    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n","    loss1_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_regularizer=l2(0.0002))(loss1_ave_pool)\n","    loss1_flat = Flatten()(loss1_conv)\n","    loss1_fc = Dense(64, activation='relu', name='loss1/fc', kernel_regularizer=l2(0.0002))(loss1_flat)\n","    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n","    loss1_classifier = Dense(classes, name='loss1/classifier', kernel_regularizer=l2(0.0002))(loss1_drop_fc)\n","    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n","\n","    inception_4b_1x1 = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_regularizer=l2(0.0002))(inception_4a_output)\n","    inception_4b_3x3_reduce = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n","    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n","    inception_4b_3x3 = Conv2D(28, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_regularizer=l2(0.0002))(inception_4b_3x3_pad)\n","    inception_4b_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n","    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n","    inception_4b_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_regularizer=l2(0.0002))(inception_4b_5x5_pad)\n","    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n","    inception_4b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_regularizer=l2(0.0002))(inception_4b_pool)\n","    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n","\n","    inception_4c_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_regularizer=l2(0.0002))(inception_4b_output)\n","    inception_4c_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n","    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n","    inception_4c_3x3 = Conv2D(32, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_regularizer=l2(0.0002))(inception_4c_3x3_pad)\n","    inception_4c_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n","    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n","    inception_4c_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_regularizer=l2(0.0002))(inception_4c_5x5_pad)\n","    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n","    inception_4c_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_regularizer=l2(0.0002))(inception_4c_pool)\n","    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n","\n","    inception_4d_1x1 = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_regularizer=l2(0.0002))(inception_4c_output)\n","    inception_4d_3x3_reduce = Conv2D(18, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n","    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n","    inception_4d_3x3 = Conv2D(36, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_regularizer=l2(0.0002))(inception_4d_3x3_pad)\n","    inception_4d_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n","    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n","    inception_4d_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_regularizer=l2(0.0002))(inception_4d_5x5_pad)\n","    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n","    inception_4d_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_regularizer=l2(0.0002))(inception_4d_pool)\n","    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n","\n","    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n","    loss2_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_regularizer=l2(0.0002))(loss2_ave_pool)\n","    loss2_flat = Flatten()(loss2_conv)\n","    loss2_fc = Dense(8, activation='relu', name='loss2/fc', kernel_regularizer=l2(0.0002))(loss2_flat)\n","    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n","    loss2_classifier = Dense(classes, name='loss2/classifier', kernel_regularizer=l2(0.0002))(loss2_drop_fc)\n","    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n","\n","    inception_4e_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_regularizer=l2(0.0002))(inception_4d_output)\n","    inception_4e_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n","    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n","    inception_4e_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_regularizer=l2(0.0002))(inception_4e_3x3_pad)\n","    inception_4e_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n","    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n","    inception_4e_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_regularizer=l2(0.0002))(inception_4e_5x5_pad)\n","    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n","    inception_4e_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_regularizer=l2(0.0002))(inception_4e_pool)\n","    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n","\n","    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n","    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n","    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool4/3x3_s2')(pool4_helper)\n","\n","    inception_5a_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n","    inception_5a_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n","    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n","    inception_5a_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_regularizer=l2(0.0002))(inception_5a_3x3_pad)\n","    inception_5a_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n","    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n","    inception_5a_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_regularizer=l2(0.0002))(inception_5a_5x5_pad)\n","    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n","    inception_5a_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_regularizer=l2(0.0002))(inception_5a_pool)\n","    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n","\n","    inception_5b_1x1 = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_regularizer=l2(0.0002))(inception_5a_output)\n","    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n","    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n","    inception_5b_3x3 = Conv2D(48, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_regularizer=l2(0.0002))(inception_5b_3x3_pad)\n","    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n","    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n","    inception_5b_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_regularizer=l2(0.0002))(inception_5b_5x5_pad)\n","    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n","    inception_5b_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_regularizer=l2(0.0002))(inception_5b_pool)\n","    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n","\n","    pool5_7x7_s1 = AveragePooling2D(pool_size=(5,5), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output) # 여기가 기존 7에서 5로 바뀐다.\n","    loss3_flat = Flatten()(pool5_7x7_s1)\n","    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n","    loss3_classifier = Dense(classes, name='loss3/classifier', kernel_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n","    loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n","\n","    googlenet = Model(inputs=input, outputs=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n","\n","\n","    if weights_path:\n","        googlenet.load_weights(weights_path)\n","\n","    # if tf.keras.backend.backend() == 'tensorflow':\n","    #     # 우리는 tf.keras를 쓰므로, 이상황은 늘 True.\n","    #     # 또한, 아래의 코드도 시행할 필요가 없다.\n","    #     # 혹시모를 , 나중의 상황에 대비해 코드만 남겨놓는다.\n","    #\n","    #     ops = []\n","    #     for layer in googlenet.layers:\n","    #         if layer.__class__.__name__ == 'Conv2D': # layer의 class의 이름이 'conv2d'이면 ~\n","    #             original_w = K.get_value(layer.kernel)\n","    #             converted_w = convert_kernel(original_w)\n","    #             ops.append(tf.assign(layer.kernel, converted_w).op)\n","    #     K.get_session().run(ops)\n","\n","    return googlenet\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zlX8DtKOHxEw","colab":{}},"source":["model = my_googlenet(input_shape=(48, 48, 3), classes=7, weights_path = None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fw2ZqjAOHxBp","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iOawzgeZGO3C","colab":{}},"source":["# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n","model.compile(optimizer='Adam', loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n","              metrics=['accuracy',macro_f1score,weighted_f1score])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QZC2AO6uGO3F","colab":{}},"source":["early_stopping = EarlyStopping(monitor = 'val_loss',patience = 4 , verbose=1,mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bpk9nH4JGO3I","colab":{}},"source":["history = model.fit(generate_train_for_three(x_train_zoom,y_train), steps_per_epoch=len(x_train)/64, validation_data= generate_valid_for_three(x_valid_zoom,y_valid), validation_steps=len(x_valid_zoom)/64, epochs=100, callbacks=[early_stopping]) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wukS_TUWGO3L","colab":{}},"source":["*_, acc, mac_f1, wei_f1 = model.evaluate(x_test,[y_test,y_test,y_test],batch_size=64)\n","print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_UH7Pq6247q","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc=history.history['prob_accuracy']\n","val_acc=history.history['val_prob_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs=range(1,len(acc)+1)\n","\n","plt.plot(epochs,acc,'b',label='training acc')\n","plt.plot(epochs,val_acc,'bo',label='validation acc')\n","plt.title('training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs,loss,'b',label='training loss')\n","plt.plot(epochs,val_loss,'bo',label='validation loss')\n","plt.title('training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dI-TsgyzlV7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3amNw2J17Y_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZ5Cl_HT17XJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKsh_zZm17Vp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdud8gE517To","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}